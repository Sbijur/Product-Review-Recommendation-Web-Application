# -*- coding: utf-8 -*-
"""Fake_Review_Detection_System_Using_SVM_LR_Model(AMAZON)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mfi7ALvUPsxjQOaihGHcei5kxDq3IMvC
"""

from google.colab import drive

drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline
import warnings, string
warnings.filterwarnings('ignore')
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import nltk
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer
from sklearn.pipeline import Pipeline
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import VotingClassifier
nltk.download('stopwords')

"""Loading and Reading the Dataset"""

df=pd.read_csv("/content/drive/MyDrive/AI Models/20191226-reviews.csv")


df.drop('asin',axis=1,inplace=True)
df.drop('name',axis=1,inplace=True)


df.dropna(inplace=True)

"""Generating Longest Review by Length"""

df['length'] = df['body'].apply(len)

"""Let's extract the largest review..."""

df[df['verified']=='True'][['body','length']].sort_values(by='length',ascending=False).head().body

"""Text Pre-Processing and Generating Bag-of-Words"""

def text_process(review):
    nopunc = [char for char in review if char not in string.punctuation]
    nopunc = ''.join(nopunc)
    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]

bow_transformer = CountVectorizer(analyzer=text_process)


bow_transformer.fit(df['body'])


review4 = df['body'][3]


bow_msg4 = bow_transformer.transform([review4])


bow_reviews = bow_transformer.transform(df['body'])



tfidf_transformer = TfidfTransformer().fit(bow_reviews)
tfidf_rev4 = tfidf_transformer.transform(bow_msg4)


tfidf_reviews = tfidf_transformer.transform(bow_reviews)


"""## Creating training and testing data

Application of SVM-LR Model
"""

X_train, X_test, y_train, y_test = train_test_split(df['body'],df['verified'],test_size=0.35)

log_reg_model = LogisticRegression()
svm_classifier = SVC(kernel='linear', probability=True)
voting_classifier = VotingClassifier(estimators=[('lr', log_reg_model), ('svm', svm_classifier)], voting='soft')

"""Generating Pipeline of SVM and LR Combination"""

pipeline = Pipeline([
    ('bow',CountVectorizer(analyzer=text_process)),
    ('tfidf',TfidfTransformer()),
    ('classifier',voting_classifier)
])

X_train=X_train.astype(str)
X_test=X_test.astype(str)
y_train=y_train.astype(str)
y_test=y_test.astype(str)


pipeline.fit(X_train,y_train)

svc_pred = pipeline.predict(X_test)


def Actual_rating(prediction):
  df=pd.read_csv("/content/drive/MyDrive/Colab Notebooks/Capstone_Project/static/TrueReviews.csv",encoding='unicode_escape')
  actual_rating=int(0)
  c=int(0)
  for i in prediction:
    actual_rating+=df['Rating'][c]
    c+=1

  if(c!=0):
    print("Number of Actual Reviews:",c)
    return(actual_rating/c)
  else:
    print("Number of Actual Reviews:")
  return 0

def Rating():
  df=pd.read_csv("/content/drive/MyDrive/Colab Notebooks/Capstone_Project/static/each_product_ALL_reviews.csv",encoding='unicode_escape')

  s=int(0)
  c=int(0)
  for i in df['Rating']:
    s=s+i
    c=c+1
  return(s/c)

def true_reviews(prediction,df):
  l=[]
  c=int(0)
  for i in prediction:
    if i=="True":
      l.append([df['Product Name'][c],df['Reviewer Name'][c],df['Rating'][c],df['Rating_full'][c],df['Rating Date'][c],df['Review_Text'][c]])
    c+=1

  d = pd.DataFrame(l, columns=['Product Name','Reviewer Name','Rating','Rating_full','Rating Date','Review_Text'])
  d.to_csv( '/content/drive/MyDrive/Colab Notebooks/Capstone_Project/static/TrueReviews.csv', index=False)
  print("Product Name:",d['Product Name'][0])
  print("True Reviews\n")
  print(d['Review_Text'])

def delete_file_contents(filename):
    with open(filename, 'w', newline='') as csvfile:
        csvfile.truncate(0)  # Truncate the file to delete its contents

def predict_function():
  filename = '/content/drive/MyDrive/Colab Notebooks/Capstone_Project/static/TrueReviews.csv'
  delete_file_contents(filename)
  #delete_file_contents(filename)
  df=pd.read_csv("/content/drive/MyDrive/Colab Notebooks/Capstone_Project/static/each_product_ALL_reviews.csv",encoding='unicode_escape')
  #df=pd.read_csv("/content/drive/MyDrive/AI Models/test.csv",encoding='unicode_escape')
  reviews=df['Review_Text'].astype(str)
  prediction=pipeline.predict(reviews)
  true_reviews(prediction,df)
  print("Product Rating Before Model Implementation:",Rating())
  print("Product Rating After Model Implementation:",Actual_rating(prediction))

